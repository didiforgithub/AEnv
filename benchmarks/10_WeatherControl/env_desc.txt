# Atmosphere Regulation Array Environment Design

## Background

The Atmosphere Regulation Array (ARA) Environment simulates the management of an alien planet's atmospheric system where the agent serves as the sole operator of a complex weather control facility. This planet operates under fundamentally different atmospheric physics than Earth, creating a challenging learning scenario where intuitive knowledge about meteorology becomes counterproductive. The planet requires precise atmospheric balance to support incoming human colonization efforts, making the agent's role critical for mission success. The alien atmospheric system exhibits non-linear interactions between weather variables, creating complex emergent behaviors that must be understood through systematic experimentation rather than prior assumptions.

## Objective

The agent must successfully stabilize the alien planet's atmosphere by maintaining the Climate Stability Index (CSI) within the critical range of 45-55 throughout the entire 30-step episode. This objective requires the agent to learn the counterintuitive atmospheric physics through trial and error while managing limited energy resources efficiently. Success is measured not only by keeping the atmosphere stable but also by demonstrating consistent control that proves the planet is suitable for long-term human habitation.

## State Setup

The environment initializes each episode with randomized starting conditions within scientifically plausible ranges for the alien planet. The initial CSI value is sampled from a uniform distribution between 40-60, ensuring episodes begin near but not necessarily within the target stability range. Temperature readings start between 200-400 alien thermal units, humidity levels range from 30-70 alien moisture units, and atmospheric pressure begins between 0.8-1.2 alien pressure units. Cloud coverage initializes between 20-80 percent, storm energy starts at 10-50 alien energy units, and solar flux begins between 800-1200 alien radiation units. The ARA energy budget starts at exactly 45 units for all episodes, and the step counter begins at zero. All weather variables are subject to natural drift patterns that generally push the system toward instability, requiring active intervention to maintain balance.

## Actions

The agent selects from six distinct atmospheric manipulation actions each step. Inject Cold Ions costs 2 energy units and secretly increases temperature while decreasing atmospheric pressure and reducing storm energy. Release Dry Fog costs 1 energy unit and counterintuitively increases humidity while decreasing cloud coverage and raising solar flux penetration. Vent Heavy Vapor costs 3 energy units and reduces temperature while increasing pressure and cloud formation. Trigger Pressure Spike costs 2 energy units and decreases humidity while increasing storm energy and atmospheric pressure. Emit Solar Net costs 1 energy unit and reduces solar flux while increasing temperature and cloud coverage. Redirect Jet Stream costs 2 energy units and affects multiple variables by increasing humidity and storm energy while decreasing pressure. Each action produces immediate changes to weather variables, but the full effects propagate through the coupled atmospheric system over the subsequent 2 steps, creating delayed feedback that requires strategic thinking.

## State Transition Rule

Weather variable transitions follow a deterministic but complex coupled dynamics model where current values depend on the previous two steps of system state and the most recent action taken. Each weather variable experiences natural drift toward destabilizing values at a rate of 1-3% per step, simulating the planet's inherently unstable atmospheric baseline. When an action is executed, it immediately applies fixed modifications to 2-4 weather variables according to the counterintuitive physics rules, then the coupled dynamics propagate these changes through interconnected atmospheric processes over exactly 2 subsequent steps. Temperature changes affect pressure and humidity with 1-step delays, humidity changes influence cloud formation and storm energy, pressure variations modify temperature and solar flux penetration, cloud coverage alters solar flux and temperature, storm energy redistributes pressure and humidity, and solar flux affects temperature and atmospheric chemistry. The Climate Stability Index recalculates each step as a weighted combination of all six normalized weather variables, where the optimal CSI value of 50 corresponds to a specific balanced configuration of atmospheric conditions.

## Rewards

The environment employs a cumulative reward structure with multiple overlapping reward events that encourage both stability maintenance and efficient learning. Stability Maintenance provides +0.5 reward every step when the CSI remains within the target range of 45-55, encouraging consistent atmospheric control. Stability Recovery grants +3.0 reward immediately when the CSI returns to the safe range after being outside it, incentivizing corrective actions. Energy Efficiency awards +0.1 reward for each unused energy unit remaining at episode termination, promoting resource conservation and strategic planning. Discovery Bonuses provide +2.0 reward the first time each action type leads to stable CSI maintenance for 3 consecutive steps, encouraging systematic exploration of the counterintuitive action effects. Perfect Episode rewards grant an additional +20.0 bonus if the CSI never leaves the safe range during all 30 steps, incentivizing mastery and consistent performance. All rewards accumulate throughout the episode with no terminal bonus structure, ensuring continuous feedback that supports incremental learning and policy refinement.

## Observation

The agent receives comprehensive atmospheric readings each step that provide sufficient information to learn effective control strategies. Observable state includes the current Climate Stability Index value with one decimal precision, the six core weather variables (temperature, humidity, atmospheric pressure, cloud coverage, storm energy, solar flux) all reported to one decimal place in alien units, the remaining ARA energy budget as an integer, and the current step counter from 0 to 30. The observation space deliberately excludes the specific mappings between actions and their effects on weather variables, requiring the agent to discover these relationships through experimentation. However, all necessary information to evaluate atmospheric stability and track system dynamics is provided, ensuring the learning task is challenging but not impossible. The delayed propagation of atmospheric changes is observable through the weather variable readings, allowing agents to develop predictive models of system behavior. Energy budget visibility supports strategic planning and resource management decisions throughout episodes.

## Termination

Episodes terminate under three specific conditions that reflect realistic operational constraints and safety parameters. Normal termination occurs when the step counter reaches 30, representing a complete operational cycle that demonstrates successful atmospheric management. Critical failure termination triggers immediately if the CSI drops below 15 or rises above 85, simulating catastrophic atmospheric conditions that would render the planet uninhabitable for colonization. Resource depletion termination occurs when the ARA energy budget reaches exactly 0 units, representing complete facility shutdown that prevents further atmospheric intervention. The episode does not terminate when individual actions become unavailable due to insufficient energy, allowing agents to continue operating with remaining viable actions until total energy depletion occurs.

## Special Features

The environment incorporates several unique mechanics that distinguish it from traditional control problems and enhance learning complexity. Counterintuitive Physics ensures that every action produces effects opposite to Earth-based atmospheric expectations, with these mappings remaining completely consistent across all episodes to support transferable learning. Coupled Atmospheric Dynamics creates realistic interdependencies between weather variables through a simplified differential equation model that produces smooth, deterministic state evolution while maintaining sufficient complexity to require strategic thinking. Delayed Feedback Propagation means action effects fully manifest over exactly 2 subsequent steps rather than immediately, requiring agents to develop temporal reasoning and predictive capabilities. Energy Constraint Management forces strategic resource allocation decisions since the initial 45 energy units must last the entire 30-step episode, adding a critical planning dimension to atmospheric control. Natural Atmospheric Drift continuously pushes weather variables toward destabilizing values, ensuring agents must maintain active intervention rather than finding static solutions. The learning environment guarantees complete consistency in physics rules, reward structures, and system dynamics across all episodes, with variability introduced only through initial condition sampling within narrow scientifically reasonable ranges.